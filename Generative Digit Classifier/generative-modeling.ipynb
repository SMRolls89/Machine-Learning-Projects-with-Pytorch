{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "unpDYYRYAue3"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.distributions import normal\n",
        "from torch.distributions import multivariate_normal"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1S-Loh4A9lt"
      },
      "source": [
        "''' Read data from txt as tensors'''\n",
        "def readData(trainFile, testFile, valFile):\n",
        "    \n",
        "    # read training data\n",
        "    train_data = np.loadtxt(trainFile)\n",
        "    train_vec = train_data[:,:-1]\n",
        "    train_lab = train_data[:,-1]\n",
        "    \n",
        "    # read testing data\n",
        "    test_data = np.loadtxt(testFile)\n",
        "    test_vec = test_data[:,:-1]\n",
        "    test_lab = test_data[:,-1]\n",
        "    \n",
        "    # read validation data\n",
        "    val_data = np.loadtxt(valFile)\n",
        "    val_vec = val_data[:,:-1]\n",
        "    val_lab = val_data[:,-1]\n",
        "    \n",
        "    return torch.tensor(train_vec), torch.tensor(train_lab), torch.tensor(test_vec), torch.tensor(test_lab), \\\n",
        "        torch.tensor(val_vec), torch.tensor(val_lab)\n",
        "\n",
        "\n",
        "# feature extractors\n",
        "'''\n",
        "    Feature extractor 0 --- only for univariate gaussian\n",
        "    input: vectors of extended image (None, 784)\n",
        "    output: sum of all pixel values for each image (None, 1)\n",
        "    '''\n",
        "def fe0(X):\n",
        "    return torch.sum(X,dim=1)\n",
        "\n",
        "'''\n",
        "    Feature extractor 1 --- only for multivariate gaussian\n",
        "    input: vectors of extended image (None, 784)\n",
        "    output: number of nonzero pixels on each row & each column.  (None, 56)\n",
        "    Remember that the input image is of size 28*28\n",
        "'''\n",
        "def fe1(X, threshold=0):\n",
        "    X_row = (X>threshold).reshape(-1,28,28).sum(dim=1)\n",
        "    X_col = (X>threshold).reshape(-1,28,28).sum(dim=2)\n",
        "    return torch.cat([X_row,X_col],dim=1).double()\n",
        "\n",
        "'''\n",
        "    Feature extractor 2 --- only for multivariate gaussian\n",
        "    input: vectors of extended image (None, 784)\n",
        "    output: input                    (None, 784)\n",
        "'''\n",
        "def fe2(X):\n",
        "    return X    # this function does nothing :( but you can build your own features if you like! :)\n",
        "\n",
        "fe = [fe0,fe1,fe2]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxR9Ax_5BKZF"
      },
      "source": [
        "class GNB:\n",
        "    '''\n",
        "    Constructor\n",
        "    input: uni - set as True for univariate model\n",
        "           ID_FE - set as 2 for fe2, otherwise don't change\n",
        "    '''\n",
        "    def __init__ (self, uni=True, ID_FE=0):\n",
        "        self.uni = uni\n",
        "        # do not change these\n",
        "        self.prior = None       # list of the priors. Made from empirical counts\n",
        "        self.dists = None       # list of Gaussian distributions likelihood. size = number of classes\n",
        "        self.num_c = 0          # number of classes\n",
        "        self.ID_FE = max(0 if self.uni else 1, ID_FE) # select feature extractor\n",
        "    \n",
        "    '''\n",
        "    Train your model\n",
        "    input: X - training data\n",
        "           y - training labels\n",
        "           uni - set as True for univariate model\n",
        "    '''\n",
        "    def train(self, X, y):\n",
        "        self.dists = list()\n",
        "        uniq_y = torch.unique(y)                      # get all labels\n",
        "        self.prior = torch.zeros(uniq_y.shape[0])     # initialize prior P(Y) to zeros\n",
        "        self.num_c = uniq_y.shape[0]                  # number of classes   \n",
        "\n",
        "        for idx in range(self.num_c):           # for each label\n",
        "            mask = torch.eq(y,idx)\n",
        "            x_by_label = X[mask]           # select all observations with label\n",
        "\n",
        "            self.prior[idx] = float( len(x_by_label) )/ len(y)              ##### TODO : Estimate your model's prior P(Y) (parts a, b, and c)\n",
        "\n",
        "            x = fe[self.ID_FE](x_by_label)      # extract the feature vector\n",
        "\n",
        "            if self.uni: ##### Univariate gaussian (parts a and b)\n",
        "\n",
        "                ########### TODO: Estimate the univariate Gaussian conditional distributions (parts a and b)           \n",
        "                ##### Hint: Compute the empirical mean and variance. Then you can call PyTorch's \"Normal\" \n",
        "                #####       function with the correct arguments to build the distribution. We have already \n",
        "                #####       imported the relevant function for you. You can refer to PyTorch's official       \n",
        "                #####       documentation for more info. \n",
        "                x_mean= torch.mean(x , dim=0)                           ##### TODO : calculate the mean value \n",
        "                x_var = torch.std( x , dim=0 )                          ##### TODO : calculate the variance\n",
        "                gaussian_dist = normal.Normal( x_mean , x_var )         ##### TODO:  replace 'None' with distribution's constructor\n",
        "\n",
        "            else: ##### Multivariate Gaussian. (part c)\n",
        "\n",
        "                ########### TODO: Estimate the multivariate Gaussian conditional distributions (part c)           \n",
        "                ##### Hint: In this part, you will call PyTorch's \"MultivariateNormal\" function to biuld    \n",
        "                #####       a multivariate normal distribution. The function is already imported.  \n",
        "                \n",
        "                # transpose the input vector for ease of usage\n",
        "                x = torch.transpose( x, 0, 1  )   \n",
        "                x_mean= torch.mean( x , dim=-1 )                                            ##### TODO: estimate the mean vector\n",
        "\n",
        "                # measure covarince\n",
        "                N = x.shape[-1]\n",
        "                x = x - x_mean.unsqueeze(-1) \n",
        "                x_cov = torch.eye(56 , dtype=torch.float64) + 1/(N-1) * x @ x.T             ##### TODO : estimate the covariance matrix\n",
        "                gaussian_dist = multivariate_normal.MultivariateNormal( x_mean , x_cov  )   #####  TODO: replace 'None' with distribution's constructor\n",
        "            \n",
        "            self.dists.append(gaussian_dist)\n",
        "        return\n",
        "\n",
        "    '''\n",
        "        Use Bayes rule to predict on one sample\n",
        "    '''\n",
        "    def predict(self, x):\n",
        "        x = fe[self.ID_FE](torch.reshape(x,(1,-1)))\n",
        "        result = [self.dists[i].log_prob(x) + torch.log(self.prior[i]) for i in range(self.num_c)]\n",
        "        return torch.argmax(torch.tensor(result))\n",
        "\n",
        "    '''\n",
        "        Evaluate classification accuracy\n",
        "    '''\n",
        "    def evaluate(self, X, y):\n",
        "        correct = 0\n",
        "        for i in range(X.shape[0]):\n",
        "            if self.predict(X[i]) == y[i].long():\n",
        "                correct = correct + 1\n",
        "        print('The classification accuracy is {:.3f}'.format(correct/X.shape[0]))\n",
        "        return"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQC0F5rbBNAh",
        "outputId": "21a405f1-6ece-4a17-9f6d-68b042eaf956"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # TODO: Replace with  correct paths to the data files (parts a, b, and c)\n",
        "    train_vec, train_lab, test_vec, test_lab, val_vec, val_lab = readData('hw0train.txt','hw0test.txt','hw0validate.txt')   \n",
        "\n",
        "    model = GNB(uni=False)  #create your model; uni - set as False for multivariate model\n",
        "\n",
        "    model.train(train_vec,train_lab)   # (parts a and b) Call univariate train function to estimate your model's parameters from the training data\n",
        "    #    train(train_vec,train_lab,False)  # (part c) Call multivariate train function to estimate your model's parameters from the training data\n",
        "\n",
        "    #    evaluate(train_vec, train_lab)    # Call evaluate function to compute classification error on the training data.\n",
        "    model.evaluate(val_vec, val_lab)        # Call evaluate function to compute classification error on the validation data.\n",
        "    #    evaluate(test_vec, test_lab)      # Call evaluate function to compute classification error on the test data.\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification accuracy is 0.832\n"
          ]
        }
      ]
    }
  ]
}